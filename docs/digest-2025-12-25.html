
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title> infoIA</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #1a1a2e;
            background-color: #f0f2f5;
        }
        
        .container {
            max-width: 700px;
            margin: 0 auto;
            background-color: #ffffff;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 28px;
            margin-bottom: 8px;
        }
        
        .header .date {
            font-size: 14px;
            opacity: 0.9;
        }
        
        .stats {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 15px;
        }
        
        .stat {
            background: rgba(255,255,255,0.2);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 13px;
        }
        
        .category-section {
            padding: 20px 25px;
            border-bottom: 1px solid #eee;
        }
        
        .category-header {
            font-size: 20px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
            color: #1a1a2e;
        }
        
        .article {
            margin-bottom: 18px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .article:hover {
            background: #f0f2f5;
        }
        
        .article-title {
            font-size: 16px;
            font-weight: 600;
            margin-bottom: 6px;
        }
        
        .article-title a {
            color: #1a1a2e;
            text-decoration: none;
        }
        
        .article-title a:hover {
            color: #667eea;
        }
        
        .article-meta {
            font-size: 12px;
            color: #666;
            margin-bottom: 8px;
        }
        
        .article-summary {
            font-size: 14px;
            color: #444;
        }
        
        .footer {
            background: #1a1a2e;
            color: #999;
            padding: 25px;
            text-align: center;
            font-size: 12px;
        }
        
        .footer a {
            color: #667eea;
        }
        
        .no-articles {
            padding: 40px;
            text-align: center;
            color: #666;
        }
        
        /* Category Colors */
        .category-releases .article { border-left-color: #10b981; }
        .category-research .article { border-left-color: #3b82f6; }
        .category-benchmarks .article { border-left-color: #f59e0b; }
        .category-industry .article { border-left-color: #8b5cf6; }
        .category-tools .article { border-left-color: #ef4444; }
        .category-spanish .article { border-left-color: #ec4899; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1> infoIA</h1>
            <div class="date">Jueves, 25 de diciembre de 2025</div>
        </div>
        
        
            
            <div class="category-section category-industry">
                <h2 class="category-header"> Noticias de Industria (8)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/the-arc-benchmarks-fall-marks-another-casualty-of-relentless-ai-optimization/" target="_blank">La ca铆da del 铆ndice de referencia ARC marca otra v铆ctima de la implacable optimizaci贸n de la IA</a>
                    </div>
                    <div class="article-summary">
                        El 铆ndice de referencia ARC, considerado durante a帽os un obst谩culo casi insuperable para los sistemas de inteligencia artificial, ya no es un desaf铆o imbatible. La optimizaci贸n constante de la tecnolog铆a ha permitido superar esta barrera, que se centraba en la fluida inteligencia en lugar de la simple memorizaci贸n. Los resultados recientes muestran que incluso este 铆ndice est谩 cayendo ante la maquinaria de optimizaci贸n implacable de la IA. Esto plantea preocupaciones sobre la capacidad de los sistemas de IA para evaluar realmente la inteligencia humana.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/" target="_blank">El aviso del sistema filtrado de Waymo revela un libro de reglas de 1200 l铆neas para su asistente Gemini en el autom贸vil</a>
                    </div>
                    <div class="article-summary">
                        La desarrolladora Jane Manchun Wong ha descubierto un libro de reglas de 1.200 l铆neas para el asistente de veh铆culos Gemini de Waymo, oculto en el c贸digo de la aplicaci贸n. Esta lista de reglas es un ejemplo destacado de ingenier铆a de promoci贸n de texto para cualquier persona que est茅 construyendo asistentes de inteligencia artificial. El c贸digo revela c贸mo Gemini debe interactuar con los usuarios y responder a diferentes situaciones.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/australias-financial-regulator-warns-banks-against-flooding-it-with-ai-generated-suspicious-activity-reports/" target="_blank">El regulador financiero de Australia advierte a los bancos que no los inunden con informes de actividades sospechosas generados por IA</a>
                    </div>
                    <div class="article-summary">
                        El regulador financiero australiano Austrac ha advertido a los bancos contra el uso excesivo de la inteligencia artificial (IA) en la creaci贸n de informes de actividades sospechosas (SARs). Seg煤n se informa, los bancos han estado generando un n煤mero excesivo de SARs utilizando IA, lo que podr铆a llevar a una sobrecarga en las autoridades reguladoras. Austrac ha instado a los bancos a utilizar la IA de manera m谩s selectiva y a centrarse en informes que tengan un alto nivel de precisi贸n. Esto busca evitar que los bancos inunden a las autoridades con informes que no tienen un valor real.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/salesforce-executives-signal-declining-trust-in-large-language-models/" target="_blank">Los ejecutivos de Salesforce se帽alan una confianza cada vez menor en los grandes modelos ling眉铆sticos</a>
                    </div>
                    <div class="article-summary">
                        Los ejecutivos de Salesforce han se帽alado una disminuci贸n en la confianza en los grandes modelos ling眉铆sticos durante este a帽o. Esta tendencia se refleja en la percepci贸n de que estos modelos no pueden proporcionar respuestas precisas y 煤tiles. Los expertos en la empresa destacan la necesidad de mejorar la precisi贸n y la relevancia de los resultados obtenidos a trav茅s de los grandes modelos ling眉铆sticos. La confianza en estos modelos ha disminuido debido a su incapacidad para proporcionar respuestas precisas y 煤tiles.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/nvidias-20-billion-groq-deal-is-really-about-blocking-googles-tpu-momentum/" target="_blank">El acuerdo de Nvidia con Groq por 20.000 millones de d贸lares en realidad tiene como objetivo bloquear el impulso de TPU de Google</a>
                    </div>
                    <div class="article-summary">
                        Nvidia ha alcanzado un acuerdo con Groq por 20.000 millones de d贸lares, lo que en realidad busca contrarrestar el impulso de los procesadores TPU de Google. El acuerdo ofrece ventajas fiscales y una defensa contra la competencia de Google en un solo movimiento. Nvidia est谩 adquiriendo un startup de chips en dificultades y sus fundadores. La transacci贸n se presenta como un "regalo de Navidad" para la empresa.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://www.technologyreview.com/2025/12/25/1130298/ai-wrapped-the-14-ai-terms-you-couldnt-avoid-in-2025/" target="_blank">AI Wrapped: Los 14 t茅rminos de IA que no podr谩s evitar en 2025</a>
                    </div>
                    <div class="article-summary">
                        La industria de la inteligencia artificial sigue en ascenso, con t茅rminos como DeepSeek, metaverso y vibro codificaci贸n que han ganado popularidad en 2025. La tecnolog铆a de IA sigue evolucionando r谩pidamente, con empresas como Meta liderando la b煤squeda de superinteligencia. A medida que se acerca el final de 2025, los expertos est谩n abordando los t茅rminos clave que definen la industria en la actualidad. La lista incluye t茅rminos como transferencia de aprendizaje y modelos de lenguaje, entre otros.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://techcrunch.com/2025/12/24/nvidia-acquires-ai-chip-challenger-groq-for-20b-report-says/" target="_blank">Nvidia otorgar谩 licencia para la tecnolog铆a del competidor de chips de IA Groq y contratar谩 a su director ejecutivo</a>
                    </div>
                    <div class="article-summary">
                        Nvidia ha anunciado que otorgar谩 licencia para su tecnolog铆a a Groq, un competidor en la fabricaci贸n de chips de IA, lo que podr铆a fortalecer su posici贸n dominante en el mercado. Adem谩s, la empresa ha contratado al director ejecutivo de Groq, quien se unir谩 a la junta directiva de Nvidia. Esta alianza podr铆a permitir a Nvidia acceder a nuevas tecnolog铆as y capacidades en la fabricaci贸n de chips de IA. La uni贸n de ambas empresas podr铆a llevar a una mayor competencia en el mercado de chips de IA.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://techcrunch.com/2025/12/24/the-year-data-centers-went-from-backend-to-center-stage/" target="_blank">El a帽o en que los centros de datos pasaron del backend al protagonismo</a>
                    </div>
                    <div class="article-summary">
                        En el 谩mbito de la tecnolog铆a, los centros de datos han dejado de ser considerados temas t茅cnicos aburridos para convertirse en protagonistas de la innovaci贸n. La creciente demanda de servicios en la nube y la adopci贸n de tecnolog铆as de inteligencia artificial han llevado a los centros de datos a desempe帽ar un papel m谩s central en la infraestructura tecnol贸gica. Esta transformaci贸n ha llevado a una mayor atenci贸n y inversi贸n en la mejora de la eficiencia, la seguridad y la escalabilidad de estos centros. Como resultado, los centros de datos est谩n evolucionando hacia una infraestructura m谩s sofisticada y resiliente.
                    </div>
                </div>
                
            </div>
            
            <div class="category-section category-releases">
                <h2 class="category-header"> Lanzamientos de Modelos (1)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://simonwillison.net/2025/Dec/24/uv-init-demos/#atom-everything" target="_blank">demostraciones-init-uv</a>
                    </div>
                    <div class="article-summary">
                        Uv Init es una herramienta 煤til para configurar proyectos de Python, pero ofrece varias opciones como --app, --package y --lib que pueden ser confusas. Para aclarar su uso, se cre贸 un repositorio de GitHub que demuestra cada una de estas opciones. Este recurso ayuda a entender mejor la configuraci贸n de uv Init en proyectos de Python.
                    </div>
                </div>
                
            </div>
            
            <div class="category-section category-research">
                <h2 class="category-header"> Research & Papers (16)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21336v1" target="_blank">Optimizaci贸n de rutas de decodificaci贸n en modelos de difusi贸n enmascarada mediante la cuantificaci贸n de la incertidumbre</a>
                    </div>
                    <div class="article-summary">
                        Los modelos de difusi贸n enmascarada (MDMs) ofrecen generaci贸n flexible y no autoregresiva, pero esta libertad introduce un desaf铆o: la calidad final del resultado es muy sensible al orden de decodificaci贸n. Se ha formalizado este problema y se ha atribuido la variabilidad en la calidad del resultado a la incertidumbre predictiva acumulada a lo largo de un camino generativo. Se ha introducido la entrop铆a denoising, una m茅trica computable que sirve como se帽al interna para evaluar el proceso generativo.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21335v1" target="_blank">Cuantificaci贸n aut贸noma de la incertidumbre para sensores computacionales en el punto de atenci贸n</a>
                    </div>
                    <div class="article-summary">
                        Los sensores de diagn贸stico de punto de atenci贸n (POC) permiten una detecci贸n r谩pida, econ贸mica y accesible en 谩reas de emergencia, remotas o con recursos limitados. Sin embargo, los modelos diagn贸sticos basados en redes neuronales pueden generar predicciones err贸neas y suposiciones, lo que pone en riesgo la diagn贸stico y las decisiones cl铆nicas. Para abordar este desaf铆o, se present贸 una t茅cnica de cuantificaci贸n aut贸noma de la incertidumbre para POC. La t茅cnica se integr贸 en una plataforma de diagn贸stico de enfermedad de Lyme, mejorando la sensibilidad y la confiabilidad del sistema en un modo aut贸nomo.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21332v1" target="_blank">Informe t茅cnico de C2LLM: una nueva frontera en la recuperaci贸n de c贸digo mediante agrupaci贸n adaptativa de atenci贸n cruzada</a>
                    </div>
                    <div class="article-summary">
                        Se presenta C2LLM, una familia de modelos de codificaci贸n de lenguaje de gran tama帽o que aprovechan la atenci贸n cruzada adaptativa para recuperar c贸digo. Estos modelos, disponibles en tama帽os de 0,5 billones y 7 billones de par谩metros, superan los registros actuales en el desaf铆o MTEB-Code, con el modelo de 7 billones de par谩metros alcanzando la primera posici贸n en el leaderboard. C2LLM utiliza un m贸dulo de atenci贸n m煤ltiple para generar una representaci贸n de secuencia a partir de las representaciones de token, lo que permite una flexibilidad y eficiencia en la representaci贸n del c贸digo.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21329v1" target="_blank">Es posible que su punto de referencia de razonamiento no pruebe el razonamiento: revelando un cuello de botella en la percepci贸n en puntos de referencia de razonamiento abstracto</a>
                    </div>
                    <div class="article-summary">
                        Un estudio reciente ha cuestionado la interpretaci贸n com煤n de que los modelos de visi贸n-idioma avanzados (VLMs) fallan en tareas de razonamiento abstracto debido a limitaciones en la raz贸n inductiva. En lugar de eso, se sugiere que la causa principal del rendimiento deficiente es la limitaci贸n en la percepci贸n visual. Un experimento de dos etapas ha demostrado que la capacidad de percepci贸n es el factor dominante que explica la brecha de rendimiento observada en los modelos VLM. Alrededor del 80% de los errores de los modelos se deben a errores de percepci贸n.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21326v1" target="_blank">Midiendo todos los ruidos de LLM Evals</a>
                    </div>
                    <div class="article-summary">
                        La medici贸n de ruidos en evaluaciones de modelos de lenguaje de largo alcance (LLM) es crucial para la ciencia experimental. Se identifican tres tipos de ruido: ruido de predicci贸n, ruido de datos y ruido total combinado. Se propone un m茅todo de an谩lisis pareado para todos los pares de modelos, lo que permite medir los componentes de ruido en millones de predicciones de nivel de pregunta en muchos evaluaciones y configuraciones. Los resultados revelan patrones claros, como un nivel de ruido total predecible en cada evaluaci贸n y un ruido de predicci贸n pareado superior al ruido de datos pareado.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="http://arxiv.org/abs/2512.21323v1" target="_blank">Predicci贸n de tokens paralelos para modelos de lenguaje</a>
                    </div>
                    <div class="article-summary">
                        Se propone un marco universal llamado Predicci贸n de Tokens Paralelos (PTP) para la generaci贸n de secuencias paralelas en modelos de lenguaje. PTP predice m煤ltiples tokens dependientes en una sola llamada de transformer, lo que reduce la latencia del decodificado autoregresivo y evita las suposiciones de independencia restrictivas comunes en los m茅todos de predicci贸n de m煤ltiples tokens existentes. PTP se puede entrenar a trav茅s de la distilaci贸n de un modelo existente o mediante entrenamiento autoregresivo inverso sin un profesor. Los resultados experimentales muestran que PTP alcanza un rendimiento de decodificaci贸n especulativa de vanguardia en Vicuna-7B, aceptando m谩s de cuatro tokens por paso en Spec-Bench.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.21338" target="_blank"> HiStream: generaci贸n eficiente de v铆deo de alta resoluci贸n mediante streaming sin redundancia</a>
                    </div>
                    <div class="article-summary">
                        Se presenta HiStream, un marco autoregresivo eficiente para la generaci贸n de v铆deo de alta resoluci贸n mediante streaming sin redundancia. Este marco reduce la complejidad computacional de los modelos de difusi贸n al aprovechar la compresi贸n espacial y temporal. La compresi贸n espacial se logra mediante la denoising en resoluci贸n baja antes de refinar la imagen en alta resoluci贸n con caracter铆sticas almacenadas. La compresi贸n temporal se logra mediante una estrategia de chunk-by-chunk con una estrategia de cach茅 de caracter铆sticas.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.21337" target="_blank"> M谩s all谩 de la memorizaci贸n: un punto de referencia de regresi贸n ordinal multimodal para exponer el sesgo de popularidad en modelos de visi贸n-lenguaje</a>
                    </div>
                    <div class="article-summary">
                        Un estudio ha expuesto un sesgo de popularidad significativo en los modelos de visi贸n-lenguaje de vanguardia, que logran una precisi贸n hasta un 34% superior en edificios famosos en comparaci贸n con los normales. Para investigar de manera sistem谩tica este fen贸meno, se ha creado el conjunto de datos YearGuessr, el m谩s grande abierto para esta tarea, que re煤ne 55.546 im谩genes de edificios con atributos multimodales de 157 pa铆ses. El conjunto de datos se ha anotado con etiquetas ordinales continuas que eval煤an la antig眉edad de los edificios.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.21252" target="_blank"> DreaMontage: generaci贸n de v铆deo one-shot guiada por fotogramas arbitrarios</a>
                    </div>
                    <div class="article-summary">
                        La t茅cnica "one-shot" en la cinematograf铆a ofrece una est茅tica sofisticada y 煤nica, pero su implementaci贸n pr谩ctica est谩 limitada por costos elevados y restricciones del mundo real complejas. Los modelos emergentes de generaci贸n de video ofrecen una alternativa virtual, pero las aproximaciones existentes suelen basarse en la concatenaci贸n de clips de manera ingenua, lo que a menudo falla en mantener la suavidad visual y la coherencia temporal. Se presenta DreaMontage, un marco integral dise帽ado para la generaci贸n de video one-shot guiada por fotogramas arbitrarios de alta calidad.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.21227" target="_blank"> PhononBench: un punto de referencia basado en fonones a gran escala para la estabilidad din谩mica en la generaci贸n de cristales</a>
                    </div>
                    <div class="article-summary">
                        Se ha desarrollado PhononBench, un punto de referencia a gran escala para evaluar la estabilidad din谩mica en cristales generados por inteligencia artificial. Este benchmark utiliza las potenciales interat贸micas de MatterSim, que logran una precisi贸n similar a la teor铆a de funci贸n de densidad en la predicci贸n de fonones para m谩s de 10.000 materiales. PhononBench permite calcular eficientemente las propiedades de fonones y la estabilidad din谩mica de 108.843 estructuras cristalinas generadas por seis modelos l铆deres de generaci贸n de cristales.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.21004" target="_blank"> Aprendiendo de la predicci贸n del siguiente fotograma: el modelado de v铆deo autorregresivo codifica representaciones efectivas</a>
                    </div>
                    <div class="article-summary">
                        Los avances recientes en el entrenamiento de modelos generales de fundaci贸n han mejorado significativamente el rendimiento en tareas diversas downstream. A diferencia de los modelos generativos autoregresivos como GPT, que han revolucionado el procesamiento de lenguaje natural, la mayor铆a de los m茅todos de preentrenamiento visual generativo siguen bas谩ndose en el modelado de m谩scaras estilo BERT, que a menudo descuida la informaci贸n temporal esencial para el an谩lisis de video. Los pocos m茅todos de preentrenamiento visual autoregresivos existentes presentan problemas como la localizaci贸n sem谩ntica inexacta y la calidad de la representaci贸n visual d茅bil.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.20757" target="_blank"> TokSuite: Medici贸n del impacto de la elecci贸n del tokenizador en el comportamiento del modelo de lenguaje</a>
                    </div>
                    <div class="article-summary">
                        TokSuite es una herramienta de investigaci贸n que eval煤a el impacto del tokenizador en el comportamiento de los modelos de lenguaje. A pesar de su importancia, el papel de la tokenizaci贸n en el rendimiento de los modelos de lenguaje es poco comprendido debido a la dificultad de medir su influencia en isolation. TokSuite consta de una colecci贸n de modelos y un benchmark que permiten investigar el efecto de la tokenizaci贸n en los modelos de lenguaje. Se han entrenado catorce modelos que utilizan diferentes tokenizadores para evaluar su influencia en el rendimiento de los modelos.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.20144" target="_blank"> Razonamiento de m煤ltiples saltos mediante la alineaci贸n temprana del conocimiento</a>
                    </div>
                    <div class="article-summary">
                        El paradigma de Retrieval-Augmented Generation (RAG) se ha convertido en un enfoque poderoso para los Modelos de Lenguaje de Gran Escala (LLMs) para abordar consultas intensivas en conocimiento que requieren informaci贸n espec铆fica de un dominio o actualizada. Para manejar preguntas complejas que requieren m煤ltiples saltos, se han propuesto enfoques iterativos de RAG que incorporan aprendizaje por refuerzo. Sin embargo, los sistemas de RAG iterativos existentes suelen descomponer preguntas sin aprovechar la informaci贸n sobre los resultados de la b煤squeda disponibles.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.18832" target="_blank"> De la palabra al mundo: 驴Pueden los modelos de lenguaje grandes ser modelos de mundo impl铆citos basados en texto?</a>
                    </div>
                    <div class="article-summary">
                        Los modelos de lenguaje grandes pueden servir como modelos de mundo impl铆citos basados en texto, lo que permitir铆a mejorar la eficiencia del aprendizaje a trav茅s de experiencias simuladas. Sin embargo, a煤n no se entiende con certeza si estos modelos pueden hacerlo de manera fiable y bajo qu茅 condiciones ser铆an beneficiosos para los agentes. En un entorno controlado basado en texto, se investigan estas preguntas para determinar la viabilidad de los modelos de lenguaje grandes como modelos de mundo.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.18470" target="_blank"> SWE-EVO: Agentes de codificaci贸n de evaluaci贸n comparativa en escenarios de evoluci贸n de software a largo plazo</a>
                    </div>
                    <div class="article-summary">
                        Se presenta SWE-EVO, un nuevo est谩ndar de evaluaci贸n para agentes de codificaci贸n de inteligencia artificial que aborda desaf铆os de largo plazo en la ingenier铆a de software. A diferencia de las pruebas existentes, SWE-EVO eval煤a a los agentes en escenarios que requieren la interpretaci贸n de requisitos generales, la planificaci贸n de cambios coordinados en m煤ltiples archivos y la evoluci贸n de bases de c贸digo a lo largo de varias iteraciones. Este nuevo est谩ndar tiene como objetivo evaluar la capacidad de los agentes para adaptarse a las necesidades cambiantes de los proyectos de software.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16093" target="_blank"> TurboDiffusion: aceleraci贸n de los modelos de difusi贸n de v铆deo entre 100 y 200 veces</a>
                    </div>
                    <div class="article-summary">
                        Se presenta TurboDiffusion, un marco de aceleraci贸n para la generaci贸n de modelos de difusi贸n de v铆deo que puede acelerar la generaci贸n de difusi贸n de v铆deo final en un factor de 100-200 sin comprometer la calidad del v铆deo. TurboDiffusion se basa principalmente en varios componentes para la aceleraci贸n, incluyendo la aceleraci贸n de atenci贸n, la destilaci贸n de paso y la cuantizaci贸n W8A8. Estas t茅cnicas permiten acelerar la generaci贸n de v铆deo y mejorar la eficiencia del proceso.
                    </div>
                </div>
                
            </div>
            
        
        
        <div class="footer">
            <p>Generado autom谩ticamente por <strong>infoIA</strong></p>
            <p>Monitoreando 18 fuentes de IA 24/7</p>
        </div>
    </div>
</body>
</html>