
<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ðŸ¤– infoIA</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #1a1a2e;
            background-color: #f0f2f5;
        }
        
        .container {
            max-width: 700px;
            margin: 0 auto;
            background-color: #ffffff;
        }
        
        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 28px;
            margin-bottom: 8px;
        }
        
        .header .date {
            font-size: 14px;
            opacity: 0.9;
        }
        
        .stats {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-top: 15px;
        }
        
        .stat {
            background: rgba(255,255,255,0.2);
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 13px;
        }
        
        .category-section {
            padding: 20px 25px;
            border-bottom: 1px solid #eee;
        }
        
        .category-header {
            font-size: 20px;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #667eea;
            color: #1a1a2e;
        }
        
        .article {
            margin-bottom: 18px;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .article:hover {
            background: #f0f2f5;
        }
        
        .article-title {
            font-size: 16px;
            font-weight: 600;
            margin-bottom: 6px;
        }
        
        .article-title a {
            color: #1a1a2e;
            text-decoration: none;
        }
        
        .article-title a:hover {
            color: #667eea;
        }
        
        .article-meta {
            font-size: 12px;
            color: #666;
            margin-bottom: 8px;
        }
        
        .article-summary {
            font-size: 14px;
            color: #444;
        }
        
        .footer {
            background: #1a1a2e;
            color: #999;
            padding: 25px;
            text-align: center;
            font-size: 12px;
        }
        
        .footer a {
            color: #667eea;
        }
        
        .no-articles {
            padding: 40px;
            text-align: center;
            color: #666;
        }
        
        /* Category Colors */
        .category-releases .article { border-left-color: #10b981; }
        .category-research .article { border-left-color: #3b82f6; }
        .category-benchmarks .article { border-left-color: #f59e0b; }
        .category-industry .article { border-left-color: #8b5cf6; }
        .category-tools .article { border-left-color: #ef4444; }
        .category-spanish .article { border-left-color: #ec4899; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ðŸ¤– infoIA</h1>
            <div class="date">Sunday, 21 de December de 2025</div>
        </div>
        
        
            
            <div class="category-section category-industry">
                <h2 class="category-header">ðŸ“° Noticias de Industria (6)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://techcrunch.com/2025/12/20/openai-allows-users-to-directly-adjust-chatgpts-warmth-and-enthusiasm/" target="_blank">OpenAI allows users to directly adjust ChatGPTâ€™s enthusiasm level</a>
                    </div>
                    <div class="article-summary">
                        ChatGPT users can now tweak the chatbotâ€™s warmth, enthusiasm, and emoji use.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://venturebeat.com/ai/hiring-specialists-made-sense-before-ai-now-generalists-win" target="_blank">Hiring specialists made sense before AI â€” now generalists win</a>
                    </div>
                    <div class="article-summary">
                        <p><i>Tony Stoyanov is CTO and co-founder of </i><a href="https://eliseai.com/"><i>EliseAI</i></a></p><p>In the 2010s, tech companies chased staff-level specialists: Backend engineers, data scientists, system architects. That model worked when technology evolved slowly. Specialists knew their craft, could deliver quickly and built careers on predictable foundations like cloud infrastructure or the latest JS framework</p><p>Then AI went mainstream.</p><p>The pace of change has exploded. New techn
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://techcrunch.com/2025/12/20/new-york-governor-kathy-hochul-signs-raise-act-to-regulate-ai-safety/" target="_blank">New York Governor Kathy Hochul signs RAISE Act to regulate AI safety</a>
                    </div>
                    <div class="article-summary">
                        The bill will require large AI developers to publish information about their safety protocols and report safety incidents to the state within 72 hours.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/telling-consumers-an-ad-is-ai-generated-cuts-clicks-by-31-percent-study-finds/" target="_blank">Telling consumers an ad is AI-generated cuts clicks by 31 percent, study finds</a>
                    </div>
                    <div class="article-summary">
                        <p><img alt="Neon running shoe with glitch-like color stripes on a green-blue banner symbolizes speed, digital dynamics" class="attachment-full size-full wp-post-image" height="768" src="https://the-decoder.com/wp-content/uploads/2025/12/AI-Generated-Banner-Ad-Nano-Banana-Pro.jpeg" style="height: auto; margin-bottom: 10px;" width="1376" /></p>
<p>        A new study from two US universities reveals a difference in how AI performs in marketing: while fully AI-generated ads significantly boost cli
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/chatgpt-gets-tone-controls-openai-adds-new-personalization-options/" target="_blank">ChatGPT gets tone controls: OpenAI adds new personalization options</a>
                    </div>
                    <div class="article-summary">
                        <p><img alt="" class="attachment-full size-full wp-post-image" height="1024" src="https://the-decoder.com/wp-content/uploads/2025/04/openai_chatgpt_logo-4.png" style="height: auto; margin-bottom: 10px;" width="1536" /></p>
<p>        OpenAI now lets users customize how ChatGPT communicates.</p>
<p>The article <a href="https://the-decoder.com/chatgpt-gets-tone-controls-openai-adds-new-personalization-options/">ChatGPT gets tone controls: OpenAI adds new personalization options</a> appeared first 
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://the-decoder.com/googles-open-standard-lets-ai-agents-build-user-interfaces-on-the-fly/" target="_blank">Google's open standard lets AI agents build user interfaces on the fly</a>
                    </div>
                    <div class="article-summary">
                        <p><img alt="Abstract Google A2UI teaser graphic with red UI map, modular pink elements and decorative geometric shapes." class="attachment-full size-full wp-post-image" height="1080" src="https://the-decoder.com/wp-content/uploads/2025/12/Google-A2UI-Teaser.jpg" style="height: auto; margin-bottom: 10px;" width="1920" /></p>
<p>        Google's new A2UI standard gives AI agents the ability to create graphical interfaces on the fly. Instead of just sending text, AIs can now generate forms, button
                    </div>
                </div>
                
            </div>
            
            <div class="category-section category-releases">
                <h2 class="category-header">ðŸš€ Lanzamientos de Modelos (3)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://docs.anthropic.com/en/release-notes/overview" target="_blank">ðŸ”„ Anthropic: OverviewClaude Developer PlatformCopy pageUpdates to the Claude Developer Platfo...</a>
                    </div>
                    <div class="article-summary">
                        New update from Anthropic. Models: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku. Check changelog for details.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://ai.google.dev/gemini-api/docs/changelog" target="_blank">ðŸ”„ Google: Gemini 3 Flash is here.Try it for free in Google AI Studio.HomeGemini APIDocsSen...</a>
                    </div>
                    <div class="article-summary">
                        New update from Google. Models: Gemini 2.0, Gemini 1.5 Pro, Gemini 1.5 Flash. Check changelog for details.
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://github.com/meta-llama/llama/releases" target="_blank">ðŸ”„ Meta: There arenâ€™t any releases here...</a>
                    </div>
                    <div class="article-summary">
                        New update from Meta. Models: Llama 3.2, Llama 3.1. Check changelog for details.
                    </div>
                </div>
                
            </div>
            
            <div class="category-section category-benchmarks">
                <h2 class="category-header">ðŸ“Š Benchmarks & Rankings (1)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://artificialanalysis.ai/" target="_blank">ðŸ“Š Artificial Analysis - Benchmark Updates</a>
                    </div>
                    <div class="article-summary">
                        Check the latest AI model benchmarks, pricing, and performance comparisons at Artificial Analysis.
                    </div>
                </div>
                
            </div>
            
            <div class="category-section category-research">
                <h2 class="category-header">ðŸ“„ Research & Papers (10)</h2>
                
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16920" target="_blank">ðŸ“‘ EasyV2V: A High-quality Instruction-based Video Editing Framework</a>
                    </div>
                    <div class="article-summary">
                        While image editing has advanced rapidly, video editing remains less explored, facing challenges in consistency, control, and generalization. We study the design space of data, architecture, and control, and introduce EasyV2V, a simple and effective framework for instruction-based video editing. On the data side, we compose existing experts with fast inverses to build diverse video pairs, lift image edit pairs into videos via single-frame supervision and pseudo pairs with shared affine motion, m
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16909" target="_blank">ðŸ“‘ MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning</a>
                    </div>
                    <div class="article-summary">
                        Mobile manipulators in households must both navigate and manipulate. This requires a compact, semantically rich scene representation that captures where objects are, how they function, and which parts are actionable. Scene graphs are a natural choice, yet prior work often separates spatial and functional relations, treats scenes as static snapshots without object states or temporal updates, and overlooks information most relevant for accomplishing the current task. To address these limitations, 
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16649" target="_blank">ðŸ“‘ JustRL: Scaling a 1.5B LLM with a Simple RL Recipe</a>
                    </div>
                    <div class="article-summary">
                        Recent advances in reinforcement learning for large language models have converged on increasing complexity: multi-stage training pipelines, dynamic hyperparameter schedules, and curriculum learning strategies. This raises a fundamental question: Is this complexity necessary? We present JustRL, a minimal approach using single-stage training with fixed hyperparameters that achieves state-of-the-art performance on two 1.5B reasoning models (54.9\% and 64.3\% average accuracy across nine mathematic
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16378" target="_blank">ðŸ“‘ Hearing to Translate: The Effectiveness of Speech Modality Integration into LLMs</a>
                    </div>
                    <div class="article-summary">
                        As Large Language Models (LLMs) expand beyond text, integrating speech as a native modality has given rise to SpeechLLMs, which aim to translate spoken language directly, thereby bypassing traditional transcription-based pipelines. Whether this integration improves speech-to-text translation quality over established cascaded architectures, however, remains an open question. We present Hearing to Translate, the first comprehensive test suite rigorously benchmarking 5 state-of-the-art SpeechLLMs a
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.16106" target="_blank">ðŸ“‘ ModelTables: A Corpus of Tables about Models</a>
                    </div>
                    <div class="article-summary">
                        We present ModelTables, a benchmark of tables in Model Lakes that captures the structured semantics of performance and configuration tables often overlooked by text only retrieval. The corpus is built from Hugging Face model cards, GitHub READMEs, and referenced papers, linking each table to its surrounding model and publication context. Compared with open data lake tables, model tables are smaller yet exhibit denser inter table relationships, reflecting tightly coupled model and benchmark evolu
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.15489" target="_blank">ðŸ“‘ Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision</a>
                    </div>
                    <div class="article-summary">
                        High-quality mathematical reasoning supervision requires diverse reasoning styles, long-form traces, and effective tool integration, capabilities that existing datasets provide only in limited form. Leveraging the multi-mode generation ability of gpt-oss-120b, we introduce Nemotron-Math, a large-scale mathematical reasoning dataset containing 7.5M solution traces across high, medium, and low reasoning modes, each available both with and without Python tool-integrated reasoning (TIR).
  The datas
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.14805" target="_blank">ðŸ“‘ Sharing State Between Prompts and Programs</a>
                    </div>
                    <div class="article-summary">
                        The rise of large language models (LLMs) has introduced a new type of programming: natural language programming. By writing prompts that direct LLMs to perform natural language processing, code generation, reasoning, etc., users are writing code in natural language -- natural language code -- for the LLM to execute.
  An emerging area of research enables interoperability between natural language code and formal languages such as Python. We present a novel programming abstraction, shared program 
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.12880" target="_blank">ðŸ“‘ Improving Recursive Transformers with Mixture of LoRAs</a>
                    </div>
                    <div class="article-summary">
                        Parameter sharing in recursive transformers reduces model size but collapses layer-wise expressivity. We propose Mixture of LoRAs (MoL), a lightweight conditional-computation mechanism that inserts Low-Rank Adaptation (LoRA) experts inside a shared feed-forward network (FFN). MoL enables token-conditional weight-space modulation of the shared FFN without untying backbone parameters, unlike prior approaches that add fixed or externally attached adapters. We pretrain a modernised recursive archite
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.12623" target="_blank">ðŸ“‘ Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space</a>
                    </div>
                    <div class="article-summary">
                        Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced cross-modal understanding and reasoning by incorporating Chain-of-Thought (CoT) reasoning in the semantic space. Building upon this, recent studies extend the CoT mechanism to the visual modality, enabling models to integrate visual information during reasoning through external tools or explicit image generation. However, these methods remain dependent on explicit step-by-step reasoning, unstable percepti
                    </div>
                </div>
                
                <div class="article">
                    <div class="article-title">
                        <a href="https://huggingface.co/papers/2512.10953" target="_blank">ðŸ“‘ Bidirectional Normalizing Flow: From Data to Noise and Back</a>
                    </div>
                    <div class="article-summary">
                        Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by com
                    </div>
                </div>
                
            </div>
            
        
        
        <div class="footer">
            <p>Generado automÃ¡ticamente por <strong>infoIA</strong></p>
            <p>Monitoreando 18 fuentes de IA 24/7</p>
        </div>
    </div>
</body>
</html>